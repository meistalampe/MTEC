
% Problem Analysis and Goals
\section{Related Work}\label{relwo}
In the past a substantial part of research in the field of Human Machine Interaction has been focused on the use of emotion recognition to give robots the ability to perceive and appropriately react to human emotions. With the appreciation of psychophysiological signals as potent markers of emotional states, a new wave of studies has been conducted on their deployment in the recognition process of adaptive human machine interaction.
We will now have a look at three studies that are closely related to ours. In this process we will investigate key aspects and show potential problems. The primary goal of all studies was to distinguish emotional states in subjects using a combination of psychophysiological measures and some machine learning technique. Measures of heart rate such as BVP or ECG, as well as galvanic skin response were used in all three as physiological indicators of emotion. In addition, respiration and EMG were used by both Maaoui and Pruski (2010) and Picard et al. (2001). Lastly, Maaoui and Pruski (2010) as well as Kim et al. (2004) employed skin temperature in their work. All measures were applied in their default measurement locations. Although, this might be acceptable for scientific settings in a lab, we argue that some of these location need to be adjusted or entirely ruled out to provide the minimum comfort to be applicable in a real-world setting. Especially, the negative effects of facial EMG, as well as the finger sensors used to measure GSR and BVP to user acceptance are easily comprehensible in an work environment where workers are physically engaged. Also, most of the sensors that were used in these studies still relied on a wired connection to deliver their data to a main processing device. A fact that further reduces practicability and in some workplaces may even increase the risk of injury.
Proceeding to the classification of emotion, we find that all three studies reported above average results. A classification accuracy of 81\% was achieved by Picard et al. (2001) while using Sequential Floating Forward Search and Fisher Projection methods to classify a total of 8 different emotional states. They used data they collected from a single subject over a time period of 30 days, with an average recording time of 25 minutes per day. Although, this method may account extremely well for daily changes in the recorded signal, it creates a  classification that is strongly dependent on a single subject. The customization of an emotion recognition system to a single user may be of interest in the final stages of implementation, but one could argue that at this stage of research a user-independent system is far more beneficial due to its universal applicability. Next, we will consider the work of Maaoui and Pruski (2010) who achieved remarkable results. They were able to reach a classification accuracy of 92\% over 6 emotions by using SVM and Fisher Linear Discriminant analysis. However they used a set of elaborate protocols for emotion
induction in combination with the IAPS and an extensive lab setting, which would again not be feasible to use in an adaptive automation workplace. Lastly, Kim et al. (2004) who attempted a user independent emotion detection system, using visually and acoustically stimuli in combination with the IAPS to elicit specific emotion in large groups (group 1: n = 125, group 2: n = 50) of children below the age of 9. Although, this strategy might be able to elicit stronger emotions that are much better represented by physiological correlates, it could be argued to be counter productive towards the generalization ability of their machine learning algorithm in an adult target population. 

\section{Problem Oriented}
Section \ref{relwo} shows that regardless of the significant accomplishments and overall advance of the field, there are still problems that are left to be resolved. As we pointed out earlier, although there were some attempts to conduct emotion recognition experiments in more realistic scenarios, the recording systems, and most of all the recording techniques (i.e. sensor locations) remained widely unimproved. Therefore, we will stray away from this pattern and use the Empatica E4, a wrist-worn system that is capable of wireless data transmission and features a single measurement site for all sensors. We believe that this is the right step towards truly unobtrusive emotion recognition allowing the field to advance by enabling more realistic experimental settings.
Another important aspect we gathered from our literature research is the apparent focus on detecting only pure emotional states. Although, this may be useful in some applications, emotions are rarely presented in this form under realistic circumstances. Considering the setting of an adaptive automation workplace we will attempt to elicit and classify more generalized mental states (e.g. is the subject feeling pleasant or unpleasant?).
%Representing different levels of workload and broader emotional areas such as pleasant and unpleasant.
Further, we will create our own database for classification including multiple subjects, representative of a working population to attempt a user independent system.
%We will not use facial emg and respiration as they are to obtrusive and choose an alternate and very localized measurement location. the wrist as most people dont feel any discomfort and are not inhibited in their movement when working.
Regarding the selection of psychophysiological measures we will comply with the studies we have presented in \ref{relwo}. However, as we have only access to a subset of these measures, we will use what is available to us: BVP, GSR, and skin temperature.
%From before we know that psychophysiological measures are an approach worth taking because they can access emotion directly , methods such as face recognition based emotion detection can be deceived more easily.
%And although there have been some approaches using psychophysiology measure in combination with ML that achieved significant scores..some problems remain.
%They used clean data sets, stationary measures, one subject only and so on
%We will attempt to evaluate measurements from multiple subjects with realistic data from the same device we could actually apply

\section{Aim, Objective, and Scope}
As mentioned before, the aim of this thesis was to facilitate the neuroergonomic assessment of human robot interaction based on the real-time measurement of psychophysiological signals using the Empatica E4 wristband. 
Meaning, we are faced with the daunting task of developing a compact emotion classification system that is capable of consistently gathering high quality data and reliably performing classification based on meaningful features.
Therefore, we focused heavily on the development of such a system, limiting our scope to the engineering, and assembling of all system components and the final evaluation, based on system performance.\\
In the following we listed all the milestones that were necessary to complete this task.

\begin{center}
\begin{enumerate}
\item[MS 1:] Development of a data extraction method that provides for real-time access on the raw signal data, as the E4 is actually designed for downstream data analysis only.
\item[MS 2:] Construction of a signal processing pipeline that compensates for artifacts while upholding signal integrity for feature extraction.
\item[MS 3:] Building a database for machine learning using authentic data gathered with our system in a series of measurements. 
\item[MS 4:] Evaluation of system capabilities using different machine learning techniques.
\end{enumerate}
\end{center}

\section{Research Questions}
\begin{center}
\begin{enumerate}
\item[RQ 1:] Is it possible to get real-time access to the data we record with the Empatica E4?
\item[RQ 2:] Is it possible to detect and distinguish different degrees of mental workload, as well as two emotional states, such as pleasant and unpleasant, using common machine learning techniques on three physiological signals that were recorded with the Empatica E4 in an experimental setting?
\item[RQ 3:] Which algorithm is best suited for the classification task introduced in RQ2?
\end{enumerate}
\end{center}
%\section{Related Work}
% outline
% https://books.google.de/books?hl=de&lr=&id=9ERRDAAAQBAJ&oi=fnd&pg=PA239&dq=neuroergonomics+adaptive+automation&ots=bvcjBrmrib&sig=xR__KHbEoDxTgcRrmyzaz6mUuX8#v=onepage&q=neuroergonomics%20adaptive%20automation&f=false
\section{Research Methodology}
In this section, we present the methodology with which we attempted to solve our research questions.\\[10pt]
 
\textbf{RQ 1:} Is it possible to get real-time access to the data we record with the Empatica E4?\\[10pt]
We approached RQ1 by researching the E4's data streaming functionality. We discovered that there was a possibility to transmit raw-data from the E4 to a Windows computer by using a streaming server application in combination with a specific USB Bluetooth receiver. The streaming server App is a developer tool provided by Empatica and can be used to register and pair, one or more Empatica devices to a certain PC. Once the pairing process is completed it is possible to access the data stream of a paired E4 device using a TCP client. We then conducted a web research on past projects involving data transmission to the Empatica streaming server. Among others we found the Empatica BLE Client for Matlab environment, developed at ICAT Virginia Tech. This TCP client was capable of storing the raw-data it received from the Empatica E4 in text files of the CSV-format. Based on these findings, we were confident to build our own TCP client, capable of providing real-time access to the raw signal data, using the Empatica web resources for developers (e.g. Documentation on message protocol, data streaming packets, and the E4 streaming server) in combination with the MATLAB environment. 
 
\textbf{RQ 2:} Is it possible to detect and distinguish different degrees of mental workload, as well as two emotional states, such as pleasant and unpleasant, using common machine learning techniques on three physiological signals (BVP, GSR, and skin temperature) that were recorded with the Empatica E4 in an experimental setting?\\[10pt]

Answering RQ2 required us to gather relevant data. We therefore conducted experiments in both, the Mindscan Lab at HTW Saar, as well as the Green Lab at the University Hospital Saarland. The recorded data was then used to evaluate the different machine learning algorithms we selected following the procedure we already described in \ref{mlsel}. 
%We therefore successfully conducted an experiment involving the measurement of BVP, GSR, and skin temperature of 14 subjects in [a] a relaxed state, [b, c] when completing two cognitive tasks, and [d, e] two tasks that were designed to elicit emotions using visual stimulation. We then used basic pre-processing methods, extracted statistical time features (mean, min, max, standard deviation) of all three signals, and a linear classifier for classification. Achieving results well above chance level we felt reassured and proceeded to develop a more elaborate data processing pipeline to provide a wide variety of high quality features to use our selected machine learning algorithms on.

\textbf{RQ 3:} Which algorithm is best suited for the classification task introduced in RQ2?\\[10pt]
The answer to RQ3 is based on the outcome of RQ2 and an evaluation of its results.
